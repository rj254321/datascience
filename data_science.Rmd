---
title: "visualization"
author: "rj2543"
date: "2/29/2020"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggplot2)
library(maps)
library(mapproj)
library(nycflights13)
library(lvplot)
```

```{r data load}
data(mpg)
mpg
```

## Aesthetic

```{r aes}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, color = "blue"))
  
mpg %>% 
  ggplot() +
  geom_point(aes(x = displ, y = hwy), color = "blue")
# mpg %>% 
#   ggplot() + 
#   geom_point(aes(x = displ, y = hwy, shape = cty))
# Error: A continuous variable can not be mapped to shape
mpg %>% 
  ggplot() +
  geom_point(aes(x = displ, y = hwy, color = cty))
mpg %>% 
  ggplot() +
  geom_point(aes(x = displ, y = hwy, size = cty))
mpg %>% 
  ggplot() +
  geom_point(aes(x = displ, y = hwy, color = cty, size = cty))
mpg %>% 
  ggplot() + 
  geom_point(aes(x = displ, y = hwy, colour = displ < 5))
# ?geom_point
# vignette("ggplot2-specs")
# The "munsell" package makes it easy to specific colours using a system designed by Alfred Munsell. If you invest a little in learning the system, it provides a convenient way of specifying aesthetically pleasing colours.
```

## Facets

One way to add additional variables is with aesthetics. Another way, particularly useful for categorical variables, is to split your plot into facets, subplots that each display one subset of the data.

```{r facet}
# To facet your plot by a single variable, use facet_wrap(). The variable that you pass to facet_wrap() should be discrete.
mpg %>% 
  ggplot() + 
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_wrap(~ class, nrow = 3)
# To facet your plot on the combination of two variables, add facet_grid() to your plot call. The first argument of facet_grid() is also a formula. This time the formula should contain two variable names separated by a ~.
mpg %>% 
  ggplot() +
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_grid(drv ~ cyl)
mpg %>% 
  ggplot() +
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_grid(. ~ cyl)
mpg %>% 
  ggplot() +
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_grid(drv ~ .)
# When using facet_grid() you should usually put the variable with more unique levels in the columns.
```

## Geometric objects

```{r geom}
mpg %>% 
  ggplot() + 
  geom_smooth(mapping = aes(x = displ, y = hwy, linetype = drv))
# In practice, ggplot2 will automatically group the data for these geoms whenever you map an aesthetic to a discrete variable (as in the linetype example). It is convenient to rely on this feature because the group aesthetic by itself does not add a legend or distinguishing features to the geoms.
mpg %>% 
  ggplot() + 
  geom_smooth(mapping = aes(x = displ, y = hwy, color = drv),
              show.legend = F)
# If you place mappings in a geom function, ggplot2 will treat them as local mappings for the layer. It will use these mappings to extend or overwrite the global mappings for that layer only. This makes it possible to display different aesthetics in different layers.
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point(mapping = aes(color = class)) + 
  geom_smooth(data = filter(mpg, class == "subcompact"), se = FALSE)
```

## Statistical transformation

```{r trans}
# You can generally use geoms and stats interchangeably. For example, you can recreate the plot using stat_count() instead of geom_bar().
ggplot(data = diamonds) + 
  stat_count(mapping = aes(x = cut))
# You might want to override the default stat. In the code below, I change the stat of geom_bar() from count (the default) to identity. This lets me map the height of the bars to the raw values of a y variable. Unfortunately when people talk about bar charts casually, they might be referring to this type of bar chart, where the height of the bar is already present in the data, or the previous bar chart where the height of the bar is generated by counting rows.
demo <- tribble(
  ~cut,         ~freq,
  "Fair",       1610,
  "Good",       4906,
  "Very Good",  12082,
  "Premium",    13791,
  "Ideal",      21551
)
demo %>% 
  mutate(cut = factor(cut, levels = c("Fair", "Good", "Very Good", "Premium", "Ideal"))) %>% 
  ggplot() +
  geom_bar(mapping = aes(x = cut, y = freq), stat = "identity")
# You might want to override the default mapping from transformed variables to aesthetics. For example, you might want to display a bar chart of proportion, rather than count.
# To find the variables computed by the stat, look for the help section titled “computed variables”.
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, y = stat(prop), group = 1))
# You might want to draw greater attention to the statistical transformation in your code. For example, you might use stat_summary(), which summarises the y values for each unique x value, to draw attention to the summary that you’re computing.
# ggplot2 provides over 20 stats for you to use. Each stat is a function, so you can get help in the usual way, e.g. ?stat_bin. To see a complete list of stats, try the ggplot2 cheatsheet.
ggplot(data = diamonds) + 
  stat_summary(
    mapping = aes(x = cut, y = depth),
    fun.ymin = min,
    fun.ymax = max,
    fun.y = median
  )
?stat_summary
?geom_col # geom_bar() makes the height of the bar proportional to the number of cases in each group (or if the weight aesthetic is supplied, the sum of the weights). If you want the heights of the bars to represent values in the data, use geom_col() instead. geom_bar() uses stat_count() by default: it counts the number of cases at each x position. geom_col() uses stat_identity(): it leaves the data as is.
?stat_smooth
?geom_bar
vignette("ggplot2-specs")
```

## Position adjustment

```{r position}
# if you map the "fill" aesthetic to another variable, like "clarity": the bars are automatically stacked. Each colored rectangle represents a combination of cut and clarity.
diamonds %>% 
  ggplot() + 
  geom_bar(mapping = aes(x = cut, fill = clarity))
# position = "fill" works like stacking, but makes each set of stacked bars the same height. This makes it easier to compare proportions across groups.
diamonds %>% 
  ggplot() + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = "fill")
# position = "dodge" places overlapping objects directly beside one another. This makes it easier to compare individual values.
diamonds %>% 
  ggplot() + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = "dodge")
# position = "jitter" adds a small amount of random noise to each point. This spreads the points out because no two points are likely to receive the same amount of random noise.
mpg %>% 
  ggplot() + 
  geom_point(mapping = aes(x = displ, y = hwy), position = "jitter")
mpg %>% 
  ggplot() +
  geom_jitter(mapping = aes(x = displ, y = hwy))
?geom_count #counts the number of observations at each location, then maps the count to point area. It useful when you have discrete data and overplotting.
mpg %>% 
  ggplot() +
  geom_count(mapping = aes(x = displ, y = hwy))
mpg %>% 
  ggplot() +
  geom_boxplot(mapping = aes(y = displ, x = trans, fill = trans), show.legend = F, position = "dodge")
# the default position adjustment for geom_boxplot() is "dodge"
```

## Coordinate systems

```{r coord}
# coord_flip() switches the x and y axes. This is useful (for example), if you want horizontal boxplots. It’s also useful for long labels: it’s hard to get them to fit without overlapping on the x-axis.
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + 
  geom_boxplot() +
  coord_flip()
# coord_quickmap() sets the aspect ratio correctly for maps. This is very important if you’re plotting spatial data with ggplot2.
nz <- map_data("nz")
ggplot(nz, aes(long, lat, group = group)) +
  geom_polygon(fill = "white", colour = "black") +
  coord_quickmap()
ggplot(nz, aes(long, lat, group = group)) +
  geom_polygon(fill = "white", colour = "black") +
  coord_map()
# coord_polar() uses polar coordinates. Polar coordinates reveal an interesting connection between a bar chart and a Coxcomb chart.
ggplot(data = diamonds) + 
  geom_bar(
    mapping = aes(x = cut, fill = cut), 
    show.legend = FALSE,
    width = 1
  ) + 
  theme(aspect.ratio = 1) +
  #labs(x = NULL, y = NULL) + 
  coord_flip()
ggplot(data = diamonds) + 
  geom_bar(
    mapping = aes(x = cut, fill = cut), 
    show.legend = FALSE,
    width = 1
  ) + 
  theme(aspect.ratio = 1) +
  labs(x = NULL, y = NULL)+ 
  coord_polar()
# coord_map projects a portion of the earth, which is approximately spherical, onto a flat 2D plane using any projection defined by the mapproj package. Map projections do not, in general, preserve straight lines, so this requires considerable computation. coord_quickmap is a quick approximation that does preserve straight lines. It works best for smaller areas closer to the equator.
ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
  geom_point() + 
  geom_abline() +
  coord_fixed()
```

## Layered grammar of graphics

ggplot(data = <DATA>) + 
  <GEOM_FUNCTION>(
     mapping = aes(<MAPPINGS>),
     stat = <STAT>, 
     position = <POSITION>
  ) +
  <COORDINATE_FUNCTION> +
  <FACET_FUNCTION>

## Work flow

Don’t be lazy and use =: it will work, but it will cause confusion later. Instead, use RStudio’s keyboard shortcut: Alt + - (the minus sign). 

```{r}
# This common action can be shortened by surrounding the assignment with parentheses, which causes assignment and “print to screen” to happen.
(y <- seq(1, 10, length.out = 5))
library(tidyverse)
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))
filter(mpg, cyl == 8)
filter(diamonds, carat > 3)
# Press Alt + Shift + K. Keyboard Shortcut Quick Reference
```

## Data Transformation

```{r filter}
(dec25 <- flights %>% 
   filter(month == 12, day == 25))
# floating point numbers: Computers use finite precision arithmetic, so remember that every number you see is an approximation.
sqrt(2)^2 == 2
near(sqrt(2) ^ 2,  2)
1/49*49 == 1
near(1 / 49 * 49, 1)
# almost any operation involving an unknown value will also be unknown
# 1. Had an arrival delay of two or more hours
flights %>% 
  filter(arr_delay >= 120)
# 2. Flew to Houston (IAH or HOU)
flights %>% 
  filter(dest %in% c("IAH", "HOU"))
# 3. Were operated by United, American, or Delta
flights %>% 
  filter(carrier %in% c("UA", "AA", "DL"))
# 4. Departed in summer (July, August, and September)
flights %>% 
  filter(month %in% c(7, 8, 9))
flights %>% 
  filter(between(month, 7, 9))
# 5. Arrived more than two hours late, but didn’t leave late
flights %>% 
  filter(arr_delay > 120 & dep_delay <= 0)
# 6. Were delayed by at least an hour, but made up over 30 minutes in flight
flights %>% 
  filter(dep_delay >= 60 & (dep_delay - arr_delay) >= 30)
# 7. Departed between midnight and 6am (inclusive)
flights %>% 
  filter(dep_time == 2400 | dep_time <= 0600)
flights %>% 
  filter(between(dep_time, 0, 600) | dep_time == 2400)
?between # This is a shortcut for x >= left & x <= right, between(x, left, right)
flights %>% 
  filter(is.na(dep_time)) # canceled flights
NA ^ 0 # = 1
NA | TRUE # TRUE
FALSE & NA # FALSE
NA * 0 # NA
```

```{r arrange}
# Missing values are always sorted at the end.
```

```{r select}
flights %>% 
  select(-(year:day))
# starts_with("abc"): matches names that begin with “abc”.
# ends_with("xyz"): matches names that end with “xyz”.
# contains("ijk"): matches names that contain “ijk”.
# matches("(.)\\1"): selects variables that match a regular expression. This one matches any variables that contain repeated characters. 
# num_range("x", 1:3): matches x1, x2 and x3.
# one_of(): Matches variable names in a character vector.
# everything(): if you have a handful of variables you’d like to move to the start of the data frame.
# last_col(): Select last variable, possibly with an offset.
vars <- c("year", "month", "day", "dep_delay", "arr_delay")
flights %>% 
  select(one_of(vars))
flights %>% 
  select(contains("TIME")) # default in the contains() helper is: ignore.case = TRUE
flights %>% 
  select(contains("TIME", ignore.case = FALSE))
```

```{r mutate}
# you can refer to columns that you’ve just created
# If you only want to keep the new variables, use transmute():
transmute(flights,
  gain = dep_delay - arr_delay,
  hours = air_time / 60,
  gain_per_hour = gain / hours
)
# Modular arithmetic: %/% (integer division) and %% (remainder), where x == y * (x %/% y) + (x %% y).
transmute(flights,
  dep_time,
  hour = dep_time %/% 100,
  minute = dep_time %% 100
)
# Offsets: lead() and lag() allow you to refer to leading or lagging values. This allows you to compute running differences (e.g. x - lag(x)) or find when values change (x != lag(x)). They are most useful in conjunction with group_by().
(x <- 1:10)
lag(x) # previous
lead(x) # next
# Cumulative and rolling aggregates: R provides functions for running sums, products, mins and maxes: cumsum(), cumprod(), cummin(), cummax(); and dplyr provides cummean() for cumulative means. If you need rolling aggregates (i.e. a sum computed over a rolling window), try the RcppRoll package.
# what is "a rolling window"?
cumsum(x)
cummean(x)
# Ranking: min_rank() does the most usual type of ranking (e.g. 1st, 2nd, 2nd, 4th). The default gives smallest values the small ranks; use desc(x) to give the largest values the smallest ranks.
y <- c(1, 2, 2, NA, 3, 4)
min_rank(y)
min_rank(desc(y))
row_number(y)
dense_rank(y)
percent_rank(y)
cume_dist(y)
# ntile(y)
flights %>% 
  transmute(air_time, arr_time - dep_time)
flights %>% 
  transmute(air_time, arr_time - dep_time, (arr_time %/% 100 * 60 + arr_time %% 100) - (dep_time %/% 100 * 60 + dep_time %% 100))
```

```{r summarise}
# grouped summaries: It collapses a data frame to a single row
# Whenever you do any aggregation, it’s always a good idea to include either a count (n()), or a count of non-missing values (sum(!is.na(x))). That way you can check that you’re not drawing conclusions based on very small amounts of data.
# median absolute deviation: mad(x)
# Measures of position: first(x), nth(x, 2), last(x). These work similarly to x[1], x[2], and x[length(x)]
# To count the number of distinct (unique) values, use n_distinct(x).

# When you group by multiple variables, each summary peels off one level of the grouping. That makes it easy to progressively roll up a dataset:
daily <- group_by(flights, year, month, day)
(per_day   <- summarise(daily, flights = n()))
(per_month <- summarise(per_day, flights = sum(flights)))
((per_year   <- summarise(per_month, flights = sum(flights))))

flights %>% group_by(carrier, dest) %>% summarise(n())

count(sort = TRUE)

vignette("window-functions")
# A window function is a variation on an aggregation function. Where an aggregation function, like sum() and mean(), takes n inputs and return a single value, a window function returns n values. The output of a window function depends on all its input values, so window functions don’t include functions that work element-wise, like + or round(). Window functions include variations on aggregate functions, like cumsum() and cummean(), functions for ranking and ordering, like rank(), and functions for taking offsets, like lead() and lag().
# lead() and lag() have an optional argument order_by. If set, instead of using the row order to determine which value comes before another, they will use another variable. This is important if you have not already sorted the data, or you want to sort one way and lag another.
```

# Exploratory Data Analysis

## Variation

```{r variation}
diamonds %>% 
  count(cut_width(carat, 0.5))

smaller <- diamonds %>% 
  filter(carat < 3)
smaller %>% 
  ggplot(aes(x = carat, color = cut)) +
  geom_freqpoly(binwidth = 0.1)

smaller %>% 
  ggplot(aes(x = carat)) + 
  geom_histogram(binwidth = 0.01)

# outlier: To make it easy to see the unusual values, we need to zoom to small values of the y-axis with coord_cartesian()
ggplot(diamonds) + 
  geom_histogram(mapping = aes(x = y), binwidth = 0.5) + # count:0 - 12000
  coord_cartesian(ylim = c(0, 50))
# It’s good practice to repeat your analysis with and without the outliers. If they have minimal effect on the results, and you can’t figure out why they’re there, it’s reasonable to replace them with missing values, and move on. However, if they have a substantial effect on your results, you shouldn’t drop them without justification. You’ll need to figure out what caused them (e.g. a data entry error) and disclose that you removed them in your write-up.
```

## Missing values

```{r missing value}
# Instead of dropping the entire observation/row with the strange values, replace the unusual values with missing values. The easiest way to do this is to use mutate() to replace the variable with a modified copy. You can use the ifelse() function to replace unusual values with NA:
diamonds2 <- diamonds %>% 
  mutate(y = ifelse(y < 3 | y > 20, NA, y))

flights %>% 
  transmute(
    cancelled = is.na(dep_time),
    sched_hour = sched_dep_time %/% 100,
    sched_min = sched_dep_time %% 100,
    sched_dep_time = sched_hour + sched_min / 60
  ) %>% 
  ggplot(mapping = aes(x = sched_dep_time)) + 
    geom_histogram(mapping = aes(fill = cancelled), binwidth = 1/4)

flights %>% 
  transmute(cancelled = is.na(dep_time),
            sched_dep_time = (sched_dep_time %/% 100) + (sched_dep_time %% 100)/60) %>% 
  ggplot(mapping = aes(x = sched_dep_time)) + 
  geom_freqpoly(mapping = aes(color = cancelled), binwidth = 1/4)
```

## Covariation

If variation describes the behavior within a variable, covariation describes the behavior between variables. 
Covariation is the tendency for the values of two or more variables to vary together in a related way. 
The best way to spot covariation is to visualise the relationship between two or more variables.

```{r categorical and continuous}
# Instead of displaying count, we’ll display density, which is the count standardised so that the area under each frequency polygon is one.
diamonds %>% 
  ggplot(mapping = aes(x = price, y = ..density..)) +
  geom_freqpoly(mapping = aes(color = cut), binwidth = 500)

# IQR. In the middle of the box is a line that displays the median. These three lines give you a sense of the spread of the distribution and whether or not the distribution is symmetric about the median or skewed to one side.
# Visual points that display observations that fall more than 1.5 times the IQR from either edge of the box. These outlying points are unusual so are plotted individually.
# A line (or whisker) that extends from each end of the box and goes to the farthest non-outlier point in the distribution.

ggplot(data = mpg) +
  geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy))
ggplot(data = mpg) +
  geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy)) +
  coord_flip() # if variable names are long

# For large datasets (10,000 - 100,000), the letter-value box plot addresses both these shortcomings: it conveys more detailed information in the tails using letter values, only out to the depths where the letter values are reliable estimates of their corresponding quantiles (corresponding to tail areas of roughly 2^{-i}); “outliers” are defined as a function of the most extreme letter value shown.
diamonds %>% 
  ggplot(mapping = aes(x = cut, y = price)) + 
  geom_lv(mapping = aes(fill = cut))

ggplot(data = mpg) +
  geom_violin(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy, fill = class))

ggplot(data = mpg) +
  geom_jitter(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy, color = class), alpha = 0.4)
```

